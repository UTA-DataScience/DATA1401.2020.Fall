{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam\n",
    "\n",
    "We will be using the [John Hopkins COVID 19 Repository](https://github.com/CSSEGISandData/COVID-19) for our final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: GIT isn't the optimal place for storing data, but nonetheless it often gets used in this way. The [John Hopkins COVID 19 Repository](https://github.com/CSSEGISandData/COVID-19) is about 1 GB of data, which is rather large. A GIT repository potentially keeps several copies of the same data. The following commands will clone the repository and remove the additional copies, leaving about 300 MB of data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/CSSEGISandData/COVID-19.git\n",
    "!rm -rf COVID-19/.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, you only need to perform this operation once. But since you are working on Google Colab, the data will be lost between sessions, unless you copy the data into your Google Drive. Download the data and copy it into your Google Drive, then comment the cell above so you don't download the data again next time you run the notebook. Note that once you copy the data, the path (location on the file system) with be different that what is assumed in the rest of this notebook. Update the following variable to reflect the change in location of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"./COVID-19/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Look through [JHU CSSE COVID-19 Dataset](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data) page to get an understanding of the contents of the dataset. You will find daily world reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $data_path/csse_covid_19_data/csse_covid_19_daily_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get a python list of the these files using glob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "us_files=glob.glob(data_path+\"csse_covid_19_data/csse_covid_19_daily_reports_us/*.csv\")\n",
    "all_files=glob.glob(data_path+\"csse_covid_19_data/csse_covid_19_daily_reports/*.csv\")\n",
    "print(len(us_files),len(all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that each file name is a date, which can be easily extracted (as example for the first file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date string from filesname\n",
    "a_date_string= all_files[0].split(\"/\")[-1].split(\".\")[0]\n",
    "print(a_date_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to sort the files, you'll have to convert the date into a sortable format. For example, here is an example of converting the date into a time-stamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,time\n",
    "time.mktime(datetime.datetime.strptime(a_date_string,\"%m-%d-%Y\").timetuple())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes in a list of files with dates as filenames and return a list with the filenames sorted by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: As we have done in lecture, you can read in the CSV files using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create time-series plots, we need to convert the aggregate the data for each row over all of the files. Create a data structure to store this information. For example, the following structure stores 2 fields,for 2 regions for 2 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"Hubei, Mainland China\" : { \"Confirmed\": [65187, 65596],\n",
    "                               \"Deaths\": [1347,2641]},\n",
    "\n",
    "  \"Guangdong, Mainland China\" :  { \"Confirmed\": [1347, 1347],\n",
    "                                   \"Deaths\": [7,7]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes the sorted list of files from previous exercise, and outputs a data structure analogous to this example, containing all of the data stored in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Write a function that takes data structure from above, name of an area, a field name, and uses `matplotlib` to make a time series plot of that field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: Write a function that takes a list of region names and the data structure from previous question and aggregate the fields over the regions, outputing a data structure that is otherwise identical to the input. Use this function to aggregate the data for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**: Develop an algorithm that identifies when COVID infections started in each region. Create a time ordered list of regions and countries of when COVID started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**: Develop an algorithm that identifies peaks in COVID infections. Use the algorithm to create lists of regions ordered by when peaks occured. Create ordered lists for regions for the first and second wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
